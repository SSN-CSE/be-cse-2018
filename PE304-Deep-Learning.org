* <<<PE304>>> DEEP LEARNING
:properties:
:author: Mr. B. Senthil Kumar and Dr. D. Thenmozhi
:date: 
:end:

#+startup: showall

{{{credits}}}
|L|T|P|C|
|3|0|0|3|

** Course Objectives
- To understand the basics of deep neural networks
- To understand CNN and RNN architectures of deep neural networks
- To comprehend the advanced deep learning models
- To learn the evaluation metrics for deep learning models

|Unit I|Deep Networks Basics|9| 
Linear Algebra: Scalars -- Vectors -- Matrices and tensors; Probability Distributions -- Gradient-based Optimization -- Machine Learning Basics: Capacity -- Overfitting and underfitting -- Hyperparameters and validation sets -- Estimators -- Bias and variance -- Stochastic gradient descent -- Challenges motivating deep learning; Deep Networks: Deep feedforward networks; Regularization -- Optimization

|Unit II|Convolutional Neural Networks|9| 
Convolution Operation -- Sparse Interactions -- Parameter Sharing -- Equivariance -- Pooling -- Convolution Variants: Strided -- Tiled -- Transposed and dilated convolutions; CNN Learning: Nonlinearity Functions -- Loss Functions -- Regularization -- Optimizers -- Gradient Computation

|Unit III|Recurrent Neural Networks|10| 
Unfolding Graphs -- RNN Design Patterns: Acceptor -- Encoder -- Transducer; Gradient Computation -- Sequence Modeling Conditioned on Contexts -- Bidirectional RNN -- Sequence to Sequence RNN -- Deep Recurrent Networks -- Recursive Neural Networks -- Long Term Dependencies; Leaky Units:  Skip connections and dropouts; Gated Architecture: LSTM

|Unit IV|Model Evaluation|8| 
Performance metrics -- Baseline Models -- Hyperparameters: Manual Hyperparameter -- Automatic Hyperparameter -- Grid search -- Random search -- Debugging strategies

|Unit V|Autoencoders and Generative Models|9| 
Autoencoders: Undercomplete autoencoders -- Regularized autoencoders -- Stochastic encoders and decoders -- Learning with autoencoders; Deep Generative Models: Variational autoencoders -- Generative adversial networks


|Total:|45|

** Course Outcomes
After the completion of this course, students will be able to: 
- Understand basics in deep neural networks (K2)
- Apply Convolution Neural Network for real-world problems in image processing (K3)
- Apply Recurrent Neural Network and its variants for text analysis (K3)
- Understand the concepts in autoencoders and generative models (K2)

** Textbook
1. Ian Goodfellow, Yoshua Bengio, Aaron Courville, "Deep Learning", MIT Press, 2016.

** References
1. Salman Khan, Hossein Rahmani, Syed Afaq Ali Shah, Mohammed Bennamoun, "A Guide to Convolutional Neural Networks for Computer Vision", Synthesis Lectures on Computer Vision, Morgan & Claypool publishers, 2018.
2. Yoav Goldberg, "Neural Network Methods for Natural Language Processing", Synthesis Lectures on Human Language Technologies, Morgan & Claypool publishers, 2017.
