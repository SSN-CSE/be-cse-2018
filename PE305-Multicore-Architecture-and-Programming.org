* <<<PE305>>> MULTICORE ARCHITECTURE AND PROGRAMMING
:properties:
:author: Ms. K. Lekshmi and Dr. D. Venkatavara Prasad
:date: 
:end:


#+begin_comment

- 1. Almost the same as AU
- 2. No changes 
- 3. Few topics of First unit in PG subject "Multicore Architectures
  and GPU Computing" are matching which is essential for understanding
  the basics. The rest of the four units are different.  With respect
  to the PG Elective paper "Parallel Programming", the following
  observations are noticed:
  + Few topics in Unit 1 of both the subjects are matched.
  + Third unit of PE305-MULTICORE ARCHITECTURE AND PROGRAMMING is
    same as fourth unit of PE231-Parallel Programming of PG syllabus.
  + Fourth unit of PE305-MULTICORE ARCHITECTURE AND PROGRAMMING
    is same as second unit of PE231-Parallel Programming of PG
    syllabus.
- 4. Five Course outcomes specified and aligned with units
- 5. Not Applicable
#+end_comment

#+startup: showall

{{{credits}}}
| L | T | P | C |
| 3 | 0 | 0 | 3 |

** COURSE OBJECTIVES
- To understand the need for multi-core processors, and their architecture. 
- To understand the challenges in parallel and multi-threaded programming. 
- To learn about the various parallel programming paradigms, 
- To develop OpenMP programs and design parallel solutions. 
- To develop an application using MPI programming 

{{{unit}}}
|UNIT I | MULTI-CORE PROCESSORS | 9 |
Single core to Multi-core architectures; SIMD and MIMD systems;
Interconnection networks; Symmetric and Distributed Shared Memory
Architectures -- Cache coherence -- Performance Issues – Parallel
program design.

{{{unit}}}
|UNIT II | PARALLEL PROGRAMMING | 9 |
Performance -- Scalability; Synchronization and data sharing -- Data
races -- Synchronization primitives (mutexes, locks, semaphores,
barriers); deadlocks and livelocks; communication between threads
(condition variables, signals, message queues and pipes).

{{{unit}}}
|UNIT III | SHARED MEMORY PROGRAMMING WITH OPENMP | 9 |
OpenMP Execution Model: Memory Model -- OpenMP Directives --
Work-sharing Constructs -- Library functions -- Handling Data and
Functional Parallelism -- Handling Loops -- Performance
Considerations.

{{{unit}}}
|UNIT IV | DISTRIBUTED MEMORY PROGRAMMING WITH MPI | 9 |
MPI program execution: MPI constructs -- libraries; MPI send and
receive -- Point-to-point and Collective communication; MPI derived
datatypes -- Performance evaluation.

{{{unit}}}
|UNIT V | PARALLEL PROGRAM DEVELOPMENT | 9 |
Case studies: n-Body solvers; Tree Search –- OpenMP and MPI
implementations and comparison.

\hfill *Total Periods: 45*

** COURSE OUTCOMES
After the completion of this course, students will be able to: 
- Understand the limitations of single core processors and the study
  various multi-core architectures (K2)
- Identify the issues in programming Parallel Processors (K2)
- Develop the programs using OpenMP (K3) 
- Develop the program using  MPI (K3)
- Compare and contrast programming for serial processors and
  programming for parallel processors (K3)
  
** TEXT BOOKS
1.  Peter S. Pacheco, ``An Introduction to Parallel Programming'',
   Morgan Kaufmann/Elsevier, 2011.
2.  Darryl Gove, ``Multicore Application Programming for Windows,
   Linux, and Oracle Solaris'', Pearson, 2011

** REFERENCES
1. Michael J Quinn, ``Parallel programming in C with MPI and OpenMP'',
   Tata McGraw Hill, 2003.
2. Victor Alessandrini, ``Shared Memory Application Programming,
   Concepts and Strategies in Multicore Application Programming'', 1st
   Edition, Morgan Kaufmann, 2015.
4. Yan Solihin, ``Fundamentals of Parallel Multicore Architecture'',
   CRC Press, 2015.
5. Rohit Chandra, Ramesh Menon, Leo Dagum, David Kohr, Dror Maydan and
   Jeff McDonald, ``Parallel Programming in OpenMP'', 1st Edition,
   Morgan Kaufmann, 2000.
7. Gerassimos Barlas, ``Multicore and GPU Programming'', Morgan
   Kaufmann, 2014.
